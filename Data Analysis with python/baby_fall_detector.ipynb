{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25df4dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(\n",
    "    static_image_mode=False,      # For video\n",
    "    model_complexity=1,           # 0=Light, 1=Full, 2=Heavy\n",
    "    smooth_landmarks=True,        # Temporal smoothing\n",
    "    enable_segmentation=False,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a42b0c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_fall_in_video(video_path, output_path=\"output_with_fall_detection.mp4\"):\n",
    "    # Open video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get video properties for output\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Create VideoWriter to save output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Variables for fall detection\n",
    "    prev_y = 0\n",
    "    prev_time = time.time()\n",
    "    velocity = 0\n",
    "    fall_detected = False\n",
    "    fall_start_frame = 0\n",
    "    fall_counter = 0\n",
    "    \n",
    "    # Process each frame\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convert BGR to RGB\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image_rgb.flags.writeable = False\n",
    "        \n",
    "        # Process with MediaPipe\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Convert back to BGR for OpenCV\n",
    "        image_rgb.flags.writeable = True\n",
    "        annotated_frame = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # FALL DETECTION LOGIC\n",
    "        if results.pose_landmarks:\n",
    "            # Draw landmarks\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_frame, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS\n",
    "            )\n",
    "            \n",
    "            # Get key landmarks\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Use mid-hip (landmarks 23 & 24 average) as reference\n",
    "            hip_y = (landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y + \n",
    "                     landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y) / 2\n",
    "            \n",
    "            # Calculate normalized height (0 to 1, where 1 is full height)\n",
    "            # Shoulder (landmark 11 & 12) to ankle (landmark 27 & 28) distance\n",
    "            shoulder_y = (landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y + \n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y) / 2\n",
    "            \n",
    "            ankle_y = (landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y + \n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y) / 2\n",
    "            \n",
    "            body_height_ratio = abs(shoulder_y - ankle_y)\n",
    "            \n",
    "            # Calculate velocity\n",
    "            current_time = time.time()\n",
    "            time_diff = current_time - prev_time\n",
    "            if time_diff > 0:\n",
    "                velocity = (hip_y - prev_y) / time_diff\n",
    "            \n",
    "            # Update previous values\n",
    "            prev_y = hip_y\n",
    "            prev_time = current_time\n",
    "            \n",
    "            # FALL DETECTION CONDITIONS\n",
    "            # Condition 1: Sudden downward velocity\n",
    "            # Condition 2: Body becomes more horizontal (height ratio decreases)\n",
    "            # Condition 3: Person is on the ground (hip close to ankle)\n",
    "            \n",
    "            if (velocity > 0.5 and              # Fast downward movement\n",
    "                body_height_ratio < 0.3 and     # Body is compressed/horizontal\n",
    "                (hip_y - ankle_y) < 0.1):       # Hip is close to ground\n",
    "                \n",
    "                if not fall_detected:\n",
    "                    fall_detected = True\n",
    "                    fall_start_frame = fall_counter\n",
    "                    print(f\"FALL DETECTED at frame {fall_counter}\")\n",
    "                \n",
    "                # Draw warning on frame\n",
    "                cv2.putText(annotated_frame, \"FALL DETECTED!\", (50, 50),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "                cv2.rectangle(annotated_frame, (0, 0), (width, height), \n",
    "                             (0, 0, 255), 10)  # Red border\n",
    "            else:\n",
    "                if fall_detected and (fall_counter - fall_start_frame > 30):\n",
    "                    fall_detected = False\n",
    "            \n",
    "            # Display metrics on frame (for debugging)\n",
    "            cv2.putText(annotated_frame, f\"Velocity: {velocity:.3f}\", (50, 100),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            cv2.putText(annotated_frame, f\"Height Ratio: {body_height_ratio:.3f}\", \n",
    "                       (50, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Write frame to output\n",
    "        out.write(annotated_frame)\n",
    "        fall_counter += 1\n",
    "        \n",
    "        # Display the frame (optional)\n",
    "        cv2.imshow('Baby Fall Detection', annotated_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    pose.close()\n",
    "    print(f\"Processing complete. Output saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fd3a811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FALL DETECTED at frame 0\n",
      "FALL DETECTED at frame 99\n",
      "Processing complete. Output saved to output_with_fall_detection.mp4\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Replace with your video file path\n",
    "    input_video = \"Fall.mp4\"\n",
    "    \n",
    "    # Check if video exists\n",
    "    import os\n",
    "    if not os.path.exists(input_video):\n",
    "        print(f\"Error: Video file '{input_video}' not found.\")\n",
    "        print(\"Please provide a valid video path.\")\n",
    "    else:\n",
    "        detect_fall_in_video(input_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea0e678",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_Learn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
